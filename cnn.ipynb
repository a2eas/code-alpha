{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator"
      ],
      "metadata": {
        "id": "TNffQgzu2rC6"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OHjUNxo92isF",
        "outputId": "1404a417-8dcd-4b84-d0c7-948ec3d1e144"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Path to dataset files: /kaggle/input/flowers-recognition\n"
          ]
        }
      ],
      "source": [
        "import kagglehub\n",
        "\n",
        "# Download latest version\n",
        "path = kagglehub.dataset_download(\"alxmamaev/flowers-recognition\")\n",
        "\n",
        "print(\"Path to dataset files:\", path)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "datagen = ImageDataGenerator(\n",
        "    rescale=1./255,\n",
        "    rotation_range=30,\n",
        "    width_shift_range=0.1,\n",
        "    height_shift_range=0.1,\n",
        "    shear_range=0.1,\n",
        "    zoom_range=0.3,\n",
        "    horizontal_flip=True,\n",
        "    fill_mode='nearest',\n",
        "    validation_split=0.2\n",
        ")"
      ],
      "metadata": {
        "id": "Jilb9Qlk2nb_"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train = datagen.flow_from_directory(\n",
        "    \"/kaggle/input/flowers-recognition/flowers\",\n",
        "    target_size=(128, 128),\n",
        "    batch_size=32,\n",
        "    class_mode='categorical', # change to catigorical in multiclass\n",
        "    subset='training', # no need if the folders is splited into train and test\n",
        "    shuffle=True\n",
        ")\n",
        "\n",
        "# Load validation images\n",
        "val = datagen.flow_from_directory(\n",
        "    \"/kaggle/input/flowers-recognition/flowers\",\n",
        "    target_size=(128, 128),\n",
        "    batch_size=32,\n",
        "    class_mode='categorical',\n",
        "    subset='validation',\n",
        "    shuffle=False\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YIBun2Ui2wa-",
        "outputId": "a55a06d4-a885-4b58-94e5-2aa3bc99d134"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 3457 images belonging to 5 classes.\n",
            "Found 860 images belonging to 5 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout, BatchNormalization,Input\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.regularizers import l2"
      ],
      "metadata": {
        "id": "VgWxAPgn3Xws"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cnn_model = Sequential()"
      ],
      "metadata": {
        "id": "FBJZVm1r3cTP"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cnn_model.add(Input(shape=(128, 128, 3)))\n",
        "cnn_model.add(Conv2D(128,(3,3),padding='same', activation='relu'))\n",
        "cnn_model.add(MaxPooling2D((2, 2)))"
      ],
      "metadata": {
        "id": "-yPa1a_W3myL"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cnn_model.add(Conv2D(64,(3,3),padding='same', activation='relu'))\n",
        "cnn_model.add(MaxPooling2D((2, 2)))\n",
        "cnn_model.add(Conv2D(16, (3, 3), activation='relu', padding='same'))\n",
        "cnn_model.add(MaxPooling2D((2, 2)))\n",
        "cnn_model.add(Conv2D(16, (3, 3), activation='relu', padding='same'))\n",
        "cnn_model.add(MaxPooling2D((2, 2)))\n",
        "cnn_model.add(Flatten()) # The connection between the CNN BLOCK anc NN Block(Fully Connected-Classifier)\n",
        "cnn_model.add(Dense(32,activation='relu'))\n",
        "cnn_model.add(Dense(24,activation='relu'))\n",
        "cnn_model.add(Dense(16,activation='relu'))\n",
        "cnn_model.add(Dense(5, activation='softmax'))\n",
        "cnn_model.compile(loss = 'categorical_crossentropy', optimizer='adam', metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "gDW7TXVje_wZ"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cnn_model.fit(train,batch_size = 32,epochs=20,validation_data=val)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OPA16kepfPzZ",
        "outputId": "28a9f5c8-a928-451e-f7f8-56d2c9852980"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "\u001b[1m109/109\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 242ms/step - accuracy: 0.6112 - loss: 0.9775 - val_accuracy: 0.5977 - val_loss: 0.9654\n",
            "Epoch 2/20\n",
            "\u001b[1m109/109\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 238ms/step - accuracy: 0.6409 - loss: 0.9550 - val_accuracy: 0.6058 - val_loss: 0.9803\n",
            "Epoch 3/20\n",
            "\u001b[1m109/109\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 240ms/step - accuracy: 0.6467 - loss: 0.9288 - val_accuracy: 0.6314 - val_loss: 0.9493\n",
            "Epoch 4/20\n",
            "\u001b[1m109/109\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 242ms/step - accuracy: 0.6387 - loss: 0.9453 - val_accuracy: 0.6233 - val_loss: 0.9645\n",
            "Epoch 5/20\n",
            "\u001b[1m109/109\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 238ms/step - accuracy: 0.6461 - loss: 0.9308 - val_accuracy: 0.6186 - val_loss: 0.9783\n",
            "Epoch 6/20\n",
            "\u001b[1m109/109\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 288ms/step - accuracy: 0.6560 - loss: 0.8728 - val_accuracy: 0.6372 - val_loss: 0.9353\n",
            "Epoch 7/20\n",
            "\u001b[1m109/109\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 241ms/step - accuracy: 0.6903 - loss: 0.8310 - val_accuracy: 0.6512 - val_loss: 0.8729\n",
            "Epoch 8/20\n",
            "\u001b[1m109/109\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 243ms/step - accuracy: 0.6972 - loss: 0.8178 - val_accuracy: 0.6465 - val_loss: 0.8994\n",
            "Epoch 9/20\n",
            "\u001b[1m109/109\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 240ms/step - accuracy: 0.6690 - loss: 0.8383 - val_accuracy: 0.6512 - val_loss: 0.8867\n",
            "Epoch 10/20\n",
            "\u001b[1m109/109\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 241ms/step - accuracy: 0.6894 - loss: 0.8145 - val_accuracy: 0.6605 - val_loss: 0.8545\n",
            "Epoch 11/20\n",
            "\u001b[1m109/109\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 240ms/step - accuracy: 0.6548 - loss: 0.8469 - val_accuracy: 0.6512 - val_loss: 0.8860\n",
            "Epoch 12/20\n",
            "\u001b[1m109/109\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 242ms/step - accuracy: 0.6913 - loss: 0.8234 - val_accuracy: 0.6837 - val_loss: 0.8155\n",
            "Epoch 13/20\n",
            "\u001b[1m109/109\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 239ms/step - accuracy: 0.7133 - loss: 0.7521 - val_accuracy: 0.6605 - val_loss: 0.8636\n",
            "Epoch 14/20\n",
            "\u001b[1m109/109\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 239ms/step - accuracy: 0.7228 - loss: 0.7394 - val_accuracy: 0.6744 - val_loss: 0.8311\n",
            "Epoch 15/20\n",
            "\u001b[1m109/109\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 240ms/step - accuracy: 0.7201 - loss: 0.7475 - val_accuracy: 0.6744 - val_loss: 0.8141\n",
            "Epoch 16/20\n",
            "\u001b[1m109/109\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 291ms/step - accuracy: 0.7113 - loss: 0.7692 - val_accuracy: 0.6930 - val_loss: 0.7893\n",
            "Epoch 17/20\n",
            "\u001b[1m109/109\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 239ms/step - accuracy: 0.7281 - loss: 0.7081 - val_accuracy: 0.6849 - val_loss: 0.8319\n",
            "Epoch 18/20\n",
            "\u001b[1m109/109\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 244ms/step - accuracy: 0.7338 - loss: 0.7043 - val_accuracy: 0.6814 - val_loss: 0.8431\n",
            "Epoch 19/20\n",
            "\u001b[1m109/109\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 248ms/step - accuracy: 0.7379 - loss: 0.6924 - val_accuracy: 0.7070 - val_loss: 0.7920\n",
            "Epoch 20/20\n",
            "\u001b[1m109/109\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 243ms/step - accuracy: 0.7490 - loss: 0.6761 - val_accuracy: 0.6919 - val_loss: 0.7978\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.history.History at 0x7b361b3158d0>"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    }
  ]
}